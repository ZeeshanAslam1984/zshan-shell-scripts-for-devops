1. Install Packages 
#!/bin/bash 
sudo apt update && sudo apt install -y nginx 
Purpose: Updates system package info and installs NGINX web server. 

 2. Monitor Disk Usage 
#!/bin/bash 
df -h > disk_usage_report.txt 
Purpose: Saves disk space usage to a file for review later.

3. Backup Files 
#!/bin/bash 
tar -czf backup_$(date +%F).tar.gz /path/to/directory 
Purpose: Compresses a directory into a .tar.gz backup file with the current date. 

4. Jenkins Job Trigger 
#!/bin/bash 
curl -X POST http://jenkins.local/job/your-job-name/build \ --user your-user:your-api-token 
Purpose: Triggers a Jenkins CI job remotely using a POST request and 
authentication. 

5. Docker Container Health Check 
#!/bin/bash 
if docker ps | grep -q my_container; then 
echo "Container is running" 
else 
echo "Container is down" 
fi 
Purpose: Checks if a specific Docker container (my_container) is running

6. System Health Check 
#!/bin/bash 
echo "CPU Load:"; uptime 
echo -e "\nMemory Usage:"; free -m 
echo -e "\nDisk Usage:"; df -h 
echo -e "\nTop 5 Memory Consuming Processes:"; ps aux --sort=-%mem | head -n 
fi
Purpose: Shows system metrics like CPU load, memory, disk, and top 
memory-consuming processes. 

7. Service Restart on Failure 
#!/bin/bash 
SERVICE="nginx" 
if ! systemctl is-active --quiet $SERVICE; then 
echo "$SERVICE is down. Restarting..." 
systemctl start $SERVICE 
else 
echo "$SERVICE is running" 
fi 
Purpose: Checks if nginx service is down and restarts it automatically. 

8. Log Rotation Script 
#!/bin/bash 
LOG_DIR="/var/log/myapp" 
ARCHIVE_DIR="/var/log/myapp/archive" 
mkdir -p $ARCHIVE_DIR 
find $LOG_DIR/*.log -mtime +7 -exec mv {} $ARCHIVE_DIR \; 
gzip $ARCHIVE_DIR/*.log 
Purpose: Moves logs older than 7 days to an archive and compresses them.

9. Git Auto Pull 
#!/bin/bash 
cd /home/ubuntu/my-repo 
git pull origin main 
Purpose: Automatically pulls the latest code from GitHub (useful with cron jobs). 

10. Docker Cleanup Script 
#!/bin/bash 
docker container prune -f 
docker image prune -f 
docker volume prune -f 
Purpose: Frees disk space by removing unused Docker containers, images, and 
volumes.

11. PostgreSQL Database Backup 
#!/bin/bash 
BACKUP_DIR="/backups" 
DB_NAME="mydb" 
USER="postgres" 
mkdir -p $BACKUP_DIR 
pg_dump -U $USER $DB_NAME > $BACKUP_DIR/${DB_NAME}_$(date 
+%F).sql 
Purpose: Creates a daily backup of a PostgreSQL database.

12. Kubernetes Pod Status Checker 
#!/bin/bash 
NAMESPACE="default" 
kubectl get pods -n $NAMESPACE | grep -v Running 
Purpose: Lists non-running pods in a Kubernetes namespace. 

13. Jenkins Job Trigger with Token 
#!/bin/bash 
JENKINS_URL="http://jenkins.local" 
JOB_NAME="my-job" 
USER="your-user" 
API_TOKEN="your-token" 
curl -X POST "$JENKINS_URL/job/$JOB_NAME/build" --user 
$USER:$API_TOKEN 
Purpose: Triggers a Jenkins job using username + token for security. 

14. Check Port Availability 
#!/bin/bash 
PORT=8080 
if lsof -i:$PORT > /dev/null; then 
echo "Port $PORT is in use." 
else 
echo "Port $PORT is free." 
fi 
Purpose: Checks if a specific port (like 8080) is being used by any process. 

15. Simple CI Build Script 
#!/bin/bash 
echo "Starting build process..." 
cd /home/ubuntu/app 
git pull origin main 
mvn clean install -DskipTests 
if [ $? -eq 0 ]; then 
echo "Build successful!" 
else 
echo "Build failed!" 
exit 1 
fi 
Purpose: A basic CI build script that pulls code and builds a Java project using 
Maven.

15. Simple CI Build Script 
#!/bin/bash 
echo "Starting build process..." 
cd /home/ubuntu/app 
git pull origin main 
mvn clean install -DskipTests 
if [ $? -eq 0 ]; then 
echo "Build successful!" 
else 
echo "Build failed!" 
exit 1 
fi 
Purpose: A basic CI build script that pulls code and builds a Java project using 
Maven. 

16. Kubernetes Rolling Restart 
#!/bin/bash 
DEPLOYMENT="myapp" 
NAMESPACE="default" 
kubectl rollout restart deployment $DEPLOYMENT -n $NAMESPACE 
● Purpose: Triggers a rolling restart of a Kubernetes deployment. 
● Use: Used to apply changes to a deployment (like new code) without 
downtime. 

17. Check Jenkins Job Status via API 
#!/bin/bash 
JOB_NAME="my-job" 
USER="admin" 
API_TOKEN="xxxxxx" 
JENKINS_URL="http://jenkins.local" 
curl -s --user $USER:$API_TOKEN 
"$JENKINS_URL/job/$JOB_NAME/lastBuild/api/json" | jq '.result' 
● Purpose: Fetches the last build status of a Jenkins job using the Jenkins API. 
● Use: Helpful for monitoring Jenkins jobs programmatically. 

18. Pull Latest Docker Image and Restart Container 
#!/bin/bash 
IMAGE="myrepo/myapp:latest" 
CONTAINER="myapp" 
docker pull $IMAGE 
docker stop $CONTAINER 
docker rm $CONTAINER 
docker run -d --name $CONTAINER -p 80:80 $IMAGE 
● Purpose: Pulls the latest Docker image, stops the existing container, 
removes it, and then restarts the container with the updated image. 
● Use: Ideal for CI/CD pipelines that require container updates. 

19. Terraform Plan & Apply with Auto-Approval 
#!/bin/bash 
cd /path/to/terraform 
terraform init 
terraform plan -out=tfplan 
terraform apply -auto-approve tfplan 
● Purpose: Automates the process of running terraform plan and applying the 
changes without manual approval. 
● Use: Useful for environments that require continuous infrastructure 
deployment

20. Ansible Playbook Trigger 
#!/bin/bash 
ansible-playbook -i inventory.ini site.yml --limit web_servers 
● Purpose: Executes an Ansible playbook on a set of hosts defined by 
web_servers in the inventory file. 
● Use: Automates configuration management tasks like provisioning or 
deploying on specific servers. 

21. Monitor CPU Usage and Send Alert 
#!/bin/bash 
THRESHOLD=80 
CPU_LOAD=$(top -bn1 | grep "Cpu(s)" | awk '{print $2 + $4}') 
if (( $(echo "$CPU_LOAD > $THRESHOLD" | bc -l) )); then 
echo "High CPU Load: $CPU_LOAD%" | mail -s "Alert: CPU Load" 
admin@example.com 
fi 
● Purpose: Monitors the CPU usage and sends an email alert if it exceeds the 
threshold (80% in this case). 
● Use: Ideal for alerting system administrators about high CPU usage. 

22. Git Branch Cleanup (Delete Merged Local Branches) 
#!/bin/bash 
git branch --merged | grep -v '\*' | grep -v main | xargs -n 1 git branch -d 
● Purpose: Deletes local Git branches that have already been merged into the 
main branch. 
● Use: Helps keep the repository clean by removing old branches that are no 
longer needed. 

23. Archive and Transfer Files to Remote Server 
#!/bin/bash 
tar -czf project_backup_$(date +%F).tar.gz /var/www/project/ 
scp project_backup_*.tar.gz user@remote:/backups/ 
● Purpose: Archives a project directory into a tarball and transfers it to a 
remote server. 
● Use: Useful for backing up project files to a remote server. 

24. SSH to Multiple Servers and Run Command 
#!/bin/bash 
SERVERS=("server1" "server2" "server3") 
for HOST in "${SERVERS[@]}" 
do 
ssh user@$HOST "uptime" 
done 
● Purpose: SSHs into multiple servers and runs the uptime command to check 
system load. 
● Use: Can be extended for running various commands on multiple servers in 
a single operation. 

25. GitHub Repo Auto Cloner 
#!/bin/bash 
REPO_LIST=("repo1" "repo2" "repo3") 
ORG="your-org" 
for REPO in "${REPO_LIST[@]}"; do 
git clone https://github.com/$ORG/$REPO.git 
done 
● Purpose: Automatically clones a list of GitHub repositories from a specific 
organization. 
● Use: Useful for setting up multiple repositories quickly. 

26. Jenkins Agent Disk Usage Check 
#!/bin/bash 
AGENTS=("agent1" "agent2") 
for AGENT in "${AGENTS[@]}" 
do 
ssh jenkins@$AGENT "df -h | grep '/$'" 
done 
● Purpose: Checks the disk usage on Jenkins agents and reports the root 
filesystem usage. 
● Use: Helpful for monitoring available disk space on Jenkins nodes. 

27. Restart All Failed Systemd Services 
#!/bin/bash 
for SERVICE in $(systemctl --failed --no-legend | awk '{print $1}'); do 
systemctl restart $SERVICE 
done 
● Purpose: Restarts all failed systemd services. 
● Use: Ensures that any failed services on a Linux system are automatically 
restarted. 

28. Pull Docker Logs for the Last 1 Hour 
#!/bin/bash 
CONTAINER="myapp" 
docker logs --since 1h $CONTAINER > logs_last_hour.txt 
● Purpose: Pulls logs from a Docker container for the last 1 hour and saves 
them to a file. 
● Use: Useful for troubleshooting and monitoring container behavior over a 
recent period. 

29. Clean Old Docker Images (Keep Last 2) 
#!/bin/bash 
docker image prune -af --filter "until=24h" 
docker images --filter=reference='myapp*' --format "{{.ID}}" | tail -n +3 | xargs 
docker rmi -f 
● Purpose: Removes old and unused Docker images, keeping only the most 
recent ones. 
● Use: Helps in cleaning up disk space by removing old Docker images that 
are no longer needed. 

30. Git Pre-Commit Hook for Code Format Check 
#!/bin/bash 
FILES=$(git diff --cached --name-only --diff-filter=ACM | grep -E '\.py$') 
for FILE in $FILES; do 
if ! black --check "$FILE"; then 
echo "Formatting error in $FILE. Run 'black $FILE'" 
exit 1 
fi 
done 
● Purpose: A pre-commit hook that checks if Python files are properly 
formatted using the black formatter before committing. 
● Use: Ensures that code follows formatting standards before it is committed 
to the Git repository

31. Auto-Deploy to Kubernetes (using kubectl) 
Script: 
#!/bin/bash 
# Define deployment variables 
DEPLOYMENT="myapp-deployment" 
NAMESPACE="default" 
IMAGE="myrepo/myapp:latest" 
# Deploy the new image to Kubernetes 
kubectl set image deployment/$DEPLOYMENT myapp=$IMAGE -n 
$NAMESPACE 
kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE 
Explanation: 
● kubectl: This is the command-line tool used to interact with Kubernetes 
clusters. 
● set image: This updates the image in the deployment to the new version. 
● rollout status: This ensures the new deployment has been successfully 
rolled out. 
● New Learner Insight: This script automates the process of deploying a new 
version of an application to a Kubernetes cluster. 

32. Docker Compose Up and Down 
Script: 
#!/bin/bash 
# Start services 
docker-compose -f /path/to/docker-compose.yml up -d 
# Stop services 
docker-compose -f /path/to/docker-compose.yml down 
Explanation: 
● docker-compose: A tool for defining and running multi-container Docker 
applications. 
● up -d: This starts the containers in detached mode (background). 
● down: This stops the containers and removes the network. 
● New Learner Insight: This script automates the start and stop process of 
multiple Docker containers defined in a docker-compose.yml file. 

33. Clean Up Docker Volumes 
Script: 
#!/bin/bash 
# List unused volumes 
docker volume ls -qf dangling=true 
# Remove all unused volumes 
docker volume prune -f 
Explanation: 
● docker volume ls -qf dangling=true: This lists all volumes that are not 
currently in use (dangling volumes). 
● docker volume prune -f: This removes all unused volumes to free up disk 
space. 
● New Learner Insight: Docker volumes can take up space if they are not 
cleaned up. This script helps remove them to save storage. 

34. SSH Key Generator Script 
Script: 
#!/bin/bash 
echo "Generating SSH key for GitHub..." 
ssh-keygen -t rsa -b 4096 -C "your_email@example.com" -f ~/.ssh/id_rsa -N "" 
# Show the public key 
cat ~/.ssh/id_rsa.pub 
Explanation: 
● ssh-keygen: This generates a new SSH key pair (public and private keys). 
● -t rsa -b 4096: This specifies the RSA algorithm with 4096 bits of 
encryption strength. 
● -f ~/.ssh/id_rsa: This saves the private key in the specified file path. 
● New Learner Insight: SSH keys are used for secure communication, such 
as connecting to servers or GitHub repositories without needing a password. 

35. CloudFormation Stack Status Check (AWS CLI) 
Script: 
#!/bin/bash 
STACK_NAME="my-cloudformation-stack" 
aws cloudformation describe-stacks --stack-name $STACK_NAME --query 
"Stacks[0].StackStatus" 
Explanation: 
● aws cloudformation describe-stacks: This AWS CLI command retrieves 
information about CloudFormation stacks. 
● --query "Stacks[0].StackStatus": This extracts the status of the specified 
stack. 
● New Learner Insight: CloudFormation is a service used to automate the 
setup of AWS resources. This script helps check the status of a stack 
deployment. 

36. Generate a Self-Signed SSL Certificate 
Script: 
#!/bin/bash 
DOMAIN="example.com" 
CERT_DIR="/etc/ssl/certs" 
KEY_DIR="/etc/ssl/private" 
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout 
$KEY_DIR/$DOMAIN.key -out $CERT_DIR/$DOMAIN.crt 
Explanation: 
● openssl req -x509: This generates a self-signed SSL certificate. 
● -newkey rsa:2048: This creates a new RSA key with 2048 bits. 
● -keyout and -out: These specify the file paths to save the private key and 
certificate. 
● New Learner Insight: SSL certificates are essential for securing 
communication over the internet. This script helps generate a self-signed 
certificate for testing purposes. 

37. Backup MySQL Database 
Script: 
#!/bin/bash 
DB_NAME="mydatabase" 
USER="root" 
PASSWORD="password" 
BACKUP_DIR="/backups" 
# Backup MySQL database 
mysqldump -u $USER -p$PASSWORD $DB_NAME > 
$BACKUP_DIR/$DB_NAME_$(date +%F).sql 
Explanation: 
● mysqldump: This command creates a backup of a MySQL database. 
● -u: Specifies the MySQL user. 
● $(date +%F): This appends the current date to the backup file for 
versioning. 
● New Learner Insight: Regular backups are essential for data safety. This 
script automates the process of backing up a MySQL database. 

38. Update System Packages (for Ubuntu/Debian) 
Script: 
#!/bin/bash 
echo "Updating system packages..." 
# Update apt repositories and upgrade packages 
sudo apt update -y && sudo apt upgrade -y 
# Clean up unused packages 
sudo apt autoremove -y 
Explanation: 
● sudo apt update -y: This updates the package index, checking for available 
updates. 
● sudo apt upgrade -y: This upgrades installed packages to their latest 
versions. 
● New Learner Insight: Keeping system packages up to date is crucial for 
security and performance. This script automates system maintenance tasks. 

39. Monitor Memory Usage and Trigger Alert 
Script: 
#!/bin/bash 
THRESHOLD=90 
MEMORY_USAGE=$(free | grep Mem | awk '{print $3/$2 * 100.0}') 
if (( $(echo "$MEMORY_USAGE > $THRESHOLD" | bc -l) )); then 
echo "Memory usage is high: $MEMORY_USAGE%" | mail -s "Alert: High 
Memory Usage" admin@example.com 
fi 
Explanation: 
● free: Displays memory usage statistics. 
● awk '{print $3/$2 * 100.0}': Calculates the percentage of used memory. 
● bc -l: This command-line calculator is used for floating-point comparison. 
● New Learner Insight: This script monitors memory usage on a system and 
sends an email alert if usage exceeds a specified threshold. 

40. Automated Version Bumping for NPM Projects 
Script: 
#!/bin/bash 
# Increment version using npm 
npm version patch 
# Push changes to Git and GitHub 
git push origin main 
git push origin --tags 
Explanation: 
● npm version patch: This increments the patch version in package.json. 
● git push origin main: This pushes the changes to the remote repository. 
● New Learner Insight: This script automates the process of versioning a 
Node.js project and pushing the new version to GitHub

41. Check Disk Usage and Send Alert 
Script: 
#!/bin/bash 
THRESHOLD=85 
DISK_USAGE=$(df / | grep / | awk '{ print $5 }' | sed 's/%//g') 
if [ $DISK_USAGE -gt $THRESHOLD ]; then 
echo "Disk usage is over threshold: $DISK_USAGE%" | mail -s "Disk Usage 
Alert" admin@example.com 
fi 
Explanation: 
● df /: Displays disk usage of the root file system. 
● awk '{ print $5 }': Extracts the percentage of disk space used. 
● sed 's/%//g': Removes the percentage sign. 
● New Learner Insight: This script monitors disk usage and sends an email 
alert if usage exceeds a specified threshold. 

42. Automatically Sync Local Repository to Remote (Git) 
Script: 
#!/bin/bash 
# Navigate to the local repository directory 
cd /path/to/repository 
# Pull the latest changes 
git pull origin main 
# Add new changes to git 
git add . 
# Commit the changes 
git commit -m "Automated commit" 
# Push the changes to the remote repository 
git push origin main 
Explanation: 
● git pull origin main: This fetches and integrates the latest changes from the 
remote repository. 
● git add .: This stages all modified files for committing. 
● git commit -m "Automated commit": This commits the changes with a 
message. 
● git push origin main: This pushes the changes to the main branch on the 
remote repository. 
● New Learner Insight: This script automates the process of syncing changes 
between a local and a remote Git repository. 

43. Clean Up Old Docker Containers 
Script: 
#!/bin/bash 
# List all containers (including stopped ones) and remove them 
docker ps -a -q | xargs docker rm -f 
Explanation: 
● docker ps -a -q: This lists all containers, including those that are stopped. 
● xargs docker rm -f: This removes each container listed by the docker ps 
command. 
● New Learner Insight: Docker containers can accumulate over time, taking 
up unnecessary space. This script removes all containers to clean up the 
system. 

44. Backup PostgreSQL Database 
Script: 
#!/bin/bash 
# Define database credentials and backup location 
DB_NAME="mydb" 
USER="postgres" 
BACKUP_DIR="/backups" 
DATE=$(date +%F) 
# Dump the PostgreSQL database 
pg_dump -U $USER $DB_NAME > $BACKUP_DIR/$DB_NAME-$DATE.sql 
Explanation: 
● pg_dump: This command creates a backup of the specified PostgreSQL 
database. 
● $DATE: The current date is added to the backup filename for versioning. 
● New Learner Insight: Regular database backups are critical. This script 
automates the process of backing up a PostgreSQL database. 

45. Monitor System Load and Send Alerts 
Script: 
#!/bin/bash 
THRESHOLD=80 
LOAD=$(uptime | awk -F'load average: ' '{ print $2 }' | cut -d, -f1 | tr -d ' ') 
if (( $(echo "$LOAD > $THRESHOLD" | bc -l) )); then 
echo "High system load: $LOAD" | mail -s "Alert: High System Load" 
admin@example.com 
fi 
Explanation: 
● uptime: This command shows how long the system has been running and 
the system load averages. 
● awk -F'load average: ': Extracts the load average from the output. 
● cut -d, -f1: Gets the 1-minute load average. 
● New Learner Insight: System load refers to the amount of computational 
work the system is performing. This script helps monitor load and send an 
alert if it exceeds a certain threshold

46. Set Up Cron Job for Regular Tasks 
Script: 
#!/bin/bash 
# Add a cron job to run the backup script every day at 2 AM 
echo "0 2 * * * /path/to/backup.sh" | crontab - 
Explanation: 
● crontab -: This sets the cron job for the current user. 
● 0 2 * * *: This specifies the time and frequency (2 AM every day). 
● New Learner Insight: A cron job is a scheduled task that automatically 
runs at specified intervals. This script adds a cron job to back up data at 2 
AM daily. 

47. Create and Configure New User on Linux 
Script: 
#!/bin/bash 
# Define username and password 
USER_NAME="newuser" 
USER_PASSWORD="password123" 
# Create the user 
sudo useradd $USER_NAME 
# Set the password for the new user 
echo "$USER_NAME:$USER_PASSWORD" | sudo chpasswd 
# Add user to sudo group 
sudo usermod -aG sudo $USER_NAME 
Explanation: 
● useradd: This creates a new user. 
● chpasswd: This sets the password for the new user. 
● usermod -aG sudo: This adds the new user to the sudo group, granting 
administrative privileges. 
● New Learner Insight: Automating user creation and management is 
common in system administration. This script sets up a user with sudo 
privileges. 

48. Check for Security Updates and Apply Them 
Script: 
#!/bin/bash 
# Update package lists 
sudo apt update 
# Install security updates 
sudo apt upgrade -y 
# Clean up unneeded packages 
sudo apt autoremove -y 
Explanation: 
● sudo apt update: Updates the list of available packages and their versions. 
● sudo apt upgrade -y: Upgrades the system, installing security patches and 
other updates. 
● sudo apt autoremove -y: Removes any unnecessary packages that were 
installed as dependencies. 
● New Learner Insight: Security updates are essential to protect systems. 
This script ensures the system is up-to-date and free of unneeded packages. 

49. Monitor Disk Usage and Alert on Threshold 
Script: 
#!/bin/bash 
THRESHOLD=90 
DISK_USAGE=$(df / | grep / | awk '{ print $5 }' | sed 's/%//g') 
if [ $DISK_USAGE -gt $THRESHOLD ]; then 
echo "Disk usage is over threshold: $DISK_USAGE%" | mail -s "Disk Usage 
Alert" admin@example.com 
fi 
Explanation: 
● df /: Shows disk space usage for the root file system. 
● awk '{ print $5 }': Extracts the disk usage percentage. 
● sed 's/%//g': Removes the % sign from the output. 
● New Learner Insight: Monitoring disk space helps avoid running out of 
space, which can cause system issues. This script sends an alert if the disk 
usage exceeds a threshold. 

50. Rotate and Backup Logs 
Script: 
#!/bin/bash 
# Define the log file 
LOG_FILE="/var/log/myapp.log" 
# Rotate log files (move to a new file with timestamp) 
mv $LOG_FILE $LOG_FILE.$(date +%F) 
# Create a new log file 
touch $LOG_FILE 
# Compress old log files 
gzip $LOG_FILE.$(date +%F) 
Explanation: 
● mv $LOG_FILE $LOG_FILE.$(date +%F): Renames the current log file 
by appending the current date to its name. 
● touch $LOG_FILE: Creates a new log file. 
● gzip: Compresses the old log file to save disk space. 
● New Learner Insight: Log rotation helps keep system logs manageable and 
prevents them from growing too large. This script automatically rotates, 
backs up, and compresses log files

51. Monitor System CPU Usage and Alert 
Script: 
#!/bin/bash 
THRESHOLD=85 
CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | sed "s/.*, *\([0-9.]*\)%* id.*/\1/" | awk 
'{print 100 - $1}') 
if [ $(echo "$CPU_USAGE > $THRESHOLD" | bc) -eq 1 ]; then 
echo "High CPU usage detected: $CPU_USAGE%" | mail -s "CPU Usage Alert" 
admin@example.com 
fi 
Explanation: 
● top -bn1: Runs top in batch mode to get a one-time output. 
● grep "Cpu(s)": Extracts the CPU usage information. 
● awk '{print 100 - $1}': Calculates the CPU usage by subtracting the idle 
percentage from 100%. 

52. Auto-deploy Application with Git Pull and Restart Service 
Script: 
#!/bin/bash 
# Define the application directory and service name 
APP_DIR="/path/to/app" 
SERVICE_NAME="myapp.service" 
# Navigate to the application directory 
cd $APP_DIR 
# Pull the latest changes from Git repository 
git pull origin main 
# Restart the application service 
sudo systemctl restart $SERVICE_NAME 
# Print a success message 
echo "Application deployed and service restarted." 
Explanation: 
● git pull origin main: Fetches the latest changes from the main branch of the 
Git repository. 
● systemctl restart $SERVICE_NAME: Restarts the specified service, 
ensuring the application runs with the latest code. 
● New Learner Insight: This script automates the process of deploying 
updated code by pulling from the repository and restarting the application 
service. 

53. Monitor Memory Usage and Send Alert 
Script: 
#!/bin/bash 
# Define the threshold for memory usage 
THRESHOLD=90 
MEMORY_USAGE=$(free | grep Mem | awk '{print $3/$2 * 100.0}') 
if (( $(echo "$MEMORY_USAGE > $THRESHOLD" | bc -l) )); then 
echo "Memory usage is over threshold: $MEMORY_USAGE%" | mail -s 
"Memory Usage Alert" admin@example.com 
fi 
Explanation: 
● free: Shows the memory usage of the system. 
● awk '{print $3/$2 * 100.0}': Calculates the percentage of memory being 
used. 
● bc -l: Performs the comparison to check if memory usage exceeds the 
threshold. 
● New Learner Insight: Memory usage monitoring is important to prevent 
the system from running out of memory, which could cause applications to 
crash. This script sends an email alert if memory usage exceeds the set 
threshold. 

54. Backup MySQL Database 
Script: 
#!/bin/bash 
# Define MySQL credentials and backup location 
DB_NAME="mydb" 
USER="root" 
PASSWORD="password" 
BACKUP_DIR="/path/to/backups" 
DATE=$(date +%F) 
# Backup MySQL database 
mysqldump -u $USER -p$PASSWORD $DB_NAME > 
$BACKUP_DIR/$DB_NAME-$DATE.sql 
# Print a success message 
echo "Backup completed successfully!" 
Explanation: 
● mysqldump: This command creates a backup of a MySQL database. 
● $BACKUP_DIR/$DB_NAME-$DATE.sql: The backup file is saved with 
the database name and the current date. 
● New Learner Insight: Backing up databases is crucial for data recovery. 
This script automates MySQL database backups. 

55. Clean Up Old Log Files 
Script: 
#!/bin/bash 
# Define the log directory and number of days to retain logs 
LOG_DIR="/var/log/myapp" 
DAYS_TO_KEEP=30 
# Find and delete log files older than the specified number of days 
find $LOG_DIR -type f -name "*.log" -mtime +$DAYS_TO_KEEP -exec rm -f {} 
\; 
# Print a success message 
echo "Old log files deleted." 
Explanation: 
● find $LOG_DIR -type f -name "*.log" -mtime +$DAYS_TO_KEEP: 
Finds log files older than the specified number of days. 
● -exec rm -f {}: Deletes each found file. 
● New Learner Insight: Log files can accumulate and take up disk space. 
This script helps clean up old log files by deleting those that are older than a 
specified number of days

56. Deploy Docker Containers Automatically 
Script: 
#!/bin/bash 
# Define Docker image and container name 
DOCKER_IMAGE="myapp:latest" 
CONTAINER_NAME="myapp_container" 
# Stop the existing container if it's running 
docker stop $CONTAINER_NAME 
# Remove the existing container 
docker rm $CONTAINER_NAME 
# Run the new container with the latest image 
docker run -d --name $CONTAINER_NAME $DOCKER_IMAGE 
# Print a success message 
echo "Docker container deployed successfully." 
Explanation: 
● docker stop $CONTAINER_NAME: Stops the running container. 
● docker rm $CONTAINER_NAME: Removes the container to prepare for 
the new one. 
● docker run -d --name $CONTAINER_NAME $DOCKER_IMAGE: 
Runs the container in detached mode using the specified Docker image. 
● New Learner Insight: This script automates the process of stopping, 
removing, and redeploying a Docker container, ensuring you always have 
the latest version of your application. 

57. Auto-Rotate SSL Certificates (for Nginx) 
Script: 
#!/bin/bash 
# Define the location of the SSL certificate and private key 
CERT_FILE="/etc/ssl/certs/myapp.crt" 
KEY_FILE="/etc/ssl/private/myapp.key" 
NGINX_CONF="/etc/nginx/nginx.conf" 
# Check if certificate is about to expire (within 30 days) 
EXPIRY_DATE=$(openssl x509 -enddate -noout -in $CERT_FILE | sed 
"s/^.*=\(.*\)$/\1/") 
EXPIRY_DATE_SECONDS=$(date --date="$EXPIRY_DATE" +%s) 
CURRENT_DATE_SECONDS=$(date +%s) 
DAYS_LEFT=$((($EXPIRY_DATE_SECONDS - 
$CURRENT_DATE_SECONDS) / 86400)) 
if [ $DAYS_LEFT -lt 30 ]; then 
# Reload Nginx configuration to apply new certificate 
sudo systemctl reload nginx 
echo "SSL certificate renewed and Nginx reloaded." 
else 
echo "No certificate renewal needed. Expiry in $DAYS_LEFT days." 
fi 
Explanation: 
● openssl x509 -enddate: Extracts the expiry date of the SSL certificate. 
● date --date="$EXPIRY_DATE" +%s: Converts the expiry date to seconds 
for comparison. 
● systemctl reload nginx: Reloads the Nginx service to apply the new 
certificate if needed. 
● New Learner Insight: Regular SSL certificate renewal ensures secure 
communication. This script checks for certificates that are about to expire 
and reloads the web server with the new certificate. 

58. Sync Files Between Servers Using Rsync 
Script: 
#!/bin/bash 
# Define source and destination directories 
SOURCE_DIR="/path/to/source" 
DEST_DIR="user@remote_server:/path/to/destination" 
# Use rsync to sync files 
rsync -avz --delete $SOURCE_DIR $DEST_DIR 
# Print a success message 
echo "Files synced successfully." 
Explanation: 
● rsync -avz: The rsync command synchronizes files and directories between 
local and remote servers. The -a option preserves attributes, -v is for 
verbosity, and -z compresses data during transfer. 
● --delete: Deletes files in the destination directory that are no longer in the 
source directory. 
● New Learner Insight: rsync is a powerful tool for syncing files. This script 
automates file transfer between two servers, ensuring they are in sync. 

59. Automatically Generate System Health Report 
Script: 
#!/bin/bash 
# Define the output file for the health report 
REPORT_FILE="/path/to/health_report.txt" 
# Get system uptime 
echo "Uptime:" >> $REPORT_FILE 
uptime >> $REPORT_FILE 
# Get disk usage 
echo "Disk Usage:" >> $REPORT_FILE 
df -h >> $REPORT_FILE 
# Get memory usage 
echo "Memory Usage:" >> $REPORT_FILE 
free -h >> $REPORT_FILE 
# Get CPU load 
echo "CPU Load:" >> $REPORT_FILE 
top -bn1 | grep "Cpu(s)" >> $REPORT_FILE 
# Print a success message 
echo "System health report generated." 
Explanation: 
● uptime: Displays how long the system has been running. 
● df -h: Shows disk space usage in a human-readable format. 
● free -h: Shows memory usage in a human-readable format. 
● top -bn1: Provides a snapshot of the system's CPU usage. 
● New Learner Insight: This script collects key system metrics and writes 
them into a health report, which can be used to monitor system health over 
time. 

60. Automatically Scale Web Server (Example with Apache) 
Script: 
#!/bin/bash 
# Define server health URL and threshold for scaling 
HEALTH_CHECK_URL="http://localhost/health" 
THRESHOLD=5 
CURRENT_LOAD=$(curl -s $HEALTH_CHECK_URL) 
if [ $CURRENT_LOAD -ge $THRESHOLD ]; then 
# Scale up the web server by adding a new instance 
echo "Scaling up the web server..." 
# Command to scale web server (e.g., launch a new instance) 
# Example: aws ec2 run-instances --image-id ami-xxxx --count 1 --instance-type 
t2.micro 
else 
echo "Load is below threshold. No scaling needed." 
fi 
Explanation: 
● curl -s $HEALTH_CHECK_URL: Fetches the health check data from a 
web server. 
● aws ec2 run-instances: (Commented out) A command that could be used to 
scale up an AWS EC2 instance if the load exceeds a threshold

61. Automated Database Migration Script 
Script: 
#!/bin/bash 
# Define the database credentials and migration directory 
DB_USER="dbuser" 
DB_PASS="dbpass" 
DB_NAME="dbname" 
MIGRATION_DIR="/path/to/migrations" 
# Run database migrations 
cd $MIGRATION_DIR 
for migration in *.sql; do 
echo "Applying migration: $migration" 
mysql -u $DB_USER -p$DB_PASS $DB_NAME < $migration 
done 
# Print a success message 
echo "All migrations applied successfully." 
Explanation: 
● mysql -u $DB_USER -p$DB_PASS $DB_NAME: Executes each 
migration SQL script against the specified MySQL database. 
● New Learner Insight: This script automates the process of running database 
migrations, which is a common task in deployment pipelines to ensure the 
database schema is up-to-date. 

62. Clean Up Docker Images 
Script: 
#!/bin/bash 
# Remove unused Docker images 
docker image prune -f 
# Remove all stopped containers 
docker container prune -f 
# Remove dangling volumes 
docker volume prune -f 
# Print a success message 
echo "Docker cleanup completed successfully." 
Explanation: 
● docker image prune -f: Removes unused Docker images to free up disk 
space. 
● docker container prune -f: Removes stopped containers. 
● docker volume prune -f: Removes unused Docker volumes. 
● New Learner Insight: Regular cleanup of Docker resources helps maintain 
system performance and free up disk space by removing unnecessary 
images, containers, and volumes. 

63. Monitor Disk Space Usage and Send Alert 
Script: 
#!/bin/bash 
# Set the disk usage threshold (in percentage) 
THRESHOLD=80 
DISK_USAGE=$(df / | grep / | awk '{ print $5 }' | sed 's/%//g') 
if [ $DISK_USAGE -gt $THRESHOLD ]; then 
echo "Disk space usage is over threshold: $DISK_USAGE%" | mail -s "Disk 
Space Alert" admin@example.com 
fi 
Explanation: 
● df /: Displays the disk usage statistics for the root directory. 
● awk '{ print $5 }': Extracts the percentage of disk space used. 
● sed 's/%//g': Removes the percentage symbol for easier comparison. 
● New Learner Insight: Disk space monitoring is crucial in production 
environments to avoid downtime or performance issues. This script sends an 
alert when the disk space usage exceeds the set threshold. 

64. Generate SSH Key Pair for Deployment 
Script: 
#!/bin/bash 
# Define the location for the SSH key 
KEY_PATH="$HOME/.ssh/deploy_key" 
# Generate a new SSH key pair 
ssh-keygen -t rsa -b 4096 -f $KEY_PATH -N "" 
# Output the public key for deployment 
cat $KEY_PATH.pub 
# Print a success message 
echo "SSH key pair generated successfully." 
Explanation: 
● ssh-keygen -t rsa -b 4096: Generates an RSA SSH key pair with a 4096-bit 
key. 
● -f $KEY_PATH: Specifies the file path where the SSH key pair will be 
stored. 
● New Learner Insight: SSH keys are used for secure authentication, 
especially in deployment scenarios. This script automates the creation of an 
SSH key pair for use in secure connections to remote servers. 

65. Backup Files to AWS S3 Bucket 
Script: 
#!/bin/bash 
# Define the source directory and S3 bucket 
SOURCE_DIR="/path/to/files" 
S3_BUCKET="s3://my-bucket/backup" 
# Sync files to the S3 bucket 
aws s3 sync $SOURCE_DIR $S3_BUCKET --delete 
# Print a success message 
echo "Backup to S3 completed successfully." 
Explanation: 
● aws s3 sync: Syncs files from the local directory to the specified S3 bucket. 
The --delete flag removes files from S3 that no longer exist locally. 
● New Learner Insight: This script automates the backup of files to AWS S3, 
which is a commonly used cloud storage solution. Syncing ensures that the 
backup is up-to-date with the local directory
